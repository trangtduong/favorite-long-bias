{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "53d769422aa81e000924c1cdead8aa1b8d790c775e85b7178f91cbdf9a124575"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## This script is used to scrape match results from www.worldfootbal.net in selected leagues in seasons 2016/17 and 2017/18."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "source": [
    "### List of URLs that contain data we want to scrape"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "with open('urls.txt', 'r') as f:\n",
    "    urls = f.readlines()\n",
    "urls = [url.strip() for url in urls]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "source": [
    "### Functions to scrape data from each url"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_league_data(url):\n",
    "    '''Extract the following information from the URL: nation, league, season.\n",
    "    '''\n",
    "    # Extract nation \n",
    "    m = re.search(r'/((eng)|(esp))-', url)\n",
    "    if not m:\n",
    "        nation = 'UEFA'\n",
    "    elif m.group(1) == 'eng':\n",
    "        nation = 'England'\n",
    "    else:\n",
    "        nation = 'Spain'\n",
    "\n",
    "    # Extract league \n",
    "    league_names_map = {\n",
    "        'champions-league': 'champions-league',\n",
    "        'championship': 'championship',\n",
    "        'premier-league': 'premier-league',\n",
    "        'league-one': 'league-one',\n",
    "        'league-two': 'league-two',\n",
    "        'national-league': 'national-league',\n",
    "        'fa-cup': 'fa-cup',\n",
    "        'league-cup': 'efl-cup',\n",
    "        'copa-del-rey': 'copa-del-rey',\n",
    "        'primera-division': 'primera',\n",
    "        'segunda': 'segunda',\n",
    "        'primera-aufstieg': 'segunda',\n",
    "    }\n",
    "    for name in league_names_map:\n",
    "        if name in url:\n",
    "            league = league_names_map[name]\n",
    "            break\n",
    "\n",
    "    # Extract season\n",
    "    season = re.search(r'\\d{2}(\\d{2})-\\d{2}(\\d{2})', url)\n",
    "    season = '/'.join([season.group(1), season.group(2)])\n",
    "    return pd.DataFrame({'nation': [nation], 'league': [league], 'season': [season]})\n",
    "\n",
    "def extract_match_data(url):\n",
    "    '''Extract match data from the page'''\n",
    "    df = pd.read_html(url)[1]\n",
    "    df.columns = ['date', 'time', 'home', \n",
    "                  'dash', 'away', 'score', 'NA']\n",
    "    \n",
    "    # Remove columns with no data\n",
    "    df.drop(columns=['dash', 'NA'], inplace=True)\n",
    "\n",
    "    # Forward fill Date columns, and drop rows that are not dates\n",
    "    df.date = df.date.ffill() \n",
    "    df.date = pd.to_datetime(df.date, format='%d/%m/%Y', errors='coerce')\n",
    "    df.dropna(axis='index', subset=['date'], inplace=True)\n",
    "\n",
    "    # Split 'score' column to 'HG' (home goal) and 'AG' (away goal) columns\n",
    "    df.score = df.score.str.split(expand=True)\n",
    "    goals = df.score.str.split(':', expand=True)\n",
    "    df['HG'], df['AG'] = goals.iloc[:, 0], goals.iloc[:, 1]\n",
    "    df.drop(columns=['score'], inplace=True)\n",
    "\n",
    "    # Create 'outcome' column\n",
    "    df['outcome'] = np.select([df.HG>df.AG, df.HG<df.AG, df.HG == df.AG],\n",
    "                              ['H', 'A', 'D'])\n",
    "    return df\n",
    "\n",
    "def extract_data(url):\n",
    "    '''Extract data from the given URL'''\n",
    "    league_data = extract_league_data(url)\n",
    "    league_data['key'] = 1\n",
    "    match_data = extract_match_data(url)\n",
    "    match_data['key'] = 1\n",
    "    return league_data.merge(match_data, on = 'key').drop(columns = ['key'])\n"
   ]
  },
  {
   "source": [
    "### Extract data from each url and concatenate to one dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(map(extract_data, urls), ignore_index=True)\n",
    "data['match_id'] = range(1, len(data)+1)\n",
    "data.to_csv('match_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}